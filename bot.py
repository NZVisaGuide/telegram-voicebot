import logging
import os
import subprocess
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    MessageHandler,
    ContextTypes,
    CommandHandler,
    filters,
)
import whisper
from openai import OpenAI

import subprocess
print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ ffmpeg:")
print(subprocess.run(["ffmpeg", "-version"], capture_output=True, text=True).stdout)


# –õ–æ–≥–∏
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Whisper model
model = whisper.load_model("base")

# OpenRouter API
openrouter_client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"
)

# /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –µ–≥–æ —Ä–∞—Å—à–∏—Ñ—Ä—É—é.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º .oga
    oga_path = "voice.oga"
    wav_path = "voice.wav"
    await file.download_to_drive(oga_path)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–µ—Ä–µ–∑ ffmpeg
    try:
        subprocess.run([
            "ffmpeg", "-y", "-i", oga_path, wav_path
        ], check=True)
    except subprocess.CalledProcessError:
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ.")
        return

    # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Whisper
    try:
        result = model.transcribe(wav_path)
        text = result["text"]
        await update.message.reply_text(f"–í—ã —Å–∫–∞–∑–∞–ª–∏: {text}")
    except Exception as e:
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏.")
        logger.error(f"Whisper error: {e}")
    finally:
        os.remove(oga_path)
        os.remove(wav_path)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text

    try:
        response = openrouter_client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[{"role": "user", "content": user_message}]
        )
        reply = response.choices[0].message.content
        await update.message.reply_text(reply)
    except Exception as e:
        logger.error(f"OpenRouter error: {e}")
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == "__main__":
    TOKEN = os.getenv("TELEGRAM_TOKEN")
    if not TOKEN:
        raise RuntimeError("TELEGRAM_TOKEN –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    app.run_polling()
